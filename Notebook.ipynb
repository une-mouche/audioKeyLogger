{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python.read_pics import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for name in os.listdir(\"data\"):\n",
    "    if name.endswith(\".bin\"):\n",
    "        files.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['NOKEY', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B' ,'C', 'D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','CTRL','ENTER','SHIFT','SPACE','SUPPR']\n",
    "\n",
    "len_labels = len(labels)\n",
    "\n",
    "input_set = []\n",
    "result_set = []\n",
    "index = 0\n",
    "\n",
    "for label in labels:\n",
    "    pics, info = get_pics_from_file('data/pics_' + label + '.bin')\n",
    "    input_set = input_set + pics[0:6963]\n",
    "    tmp = [0] * len_labels\n",
    "    tmp[index] = 1\n",
    "    index += 1\n",
    "    #for i in range(info[\"nb_trames\"] - 1):\n",
    "    for i in range(6963):\n",
    "        result_set.append(tmp)\n",
    "\n",
    "input_set = np.array(input_set)\n",
    "result_set = np.array(result_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(file, frame):\n",
    "    model = tf.keras.models.load_model(file)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    array = tf.expand_dims(frame, 0)\n",
    "\n",
    "    predictions = model.predict_on_batch(array)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __predict(model, frame):\n",
    "    array = tf.expand_dims(frame, 0)\n",
    "\n",
    "    predictions = model.predict_on_batch(array)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=3)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "opt = SGD(lr=0.1, momentum=0.9)\n",
    "input_train, input_test, output_train, output_test = train_test_split(input_set, result_set, test_size=0.33)\n",
    "\n",
    "# determine the number of input features\n",
    "n_features = X_train.shape[1]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(17, activation='relu', input_shape=(n_features,)))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(3000, activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(42, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "# fit the model\n",
    "model.fit(input_train, output_train, epochs=1000, batch_size=32, verbose=1, validation_data=(input_test, output_test), callbacks=callbacks)\n",
    "# evaluate the model\n",
    "error = model.evaluate(input_test, output_test)\n",
    "model.save(\"weight.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "\n",
    "input_train, input_test, output_train, output_test = train_test_split(input_set, result_set, test_size=0.33)\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(\"E:/Hackaton/audioKeyLoger/53percent.h5\")\n",
    "# compile the model\n",
    "# model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "# fit the model\n",
    "model.fit(input_train, output_train, epochs=1000, batch_size=32, verbose=1, validation_data=(input_test, output_test), callbacks=callbacks)\n",
    "# evaluate the model\n",
    "error = model.evaluate(input_test, output_test)\n",
    "model.save(\"weight.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debrief(predictions):\n",
    "    index = np.argmax(predictions)\n",
    "    return labels[index], index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keylogger():\n",
    "    \n",
    "    model = tf.keras.models.load_model(\"58percent.h5\")\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"])\n",
    "    \n",
    "    frames, info = get_pics_from_file('pics_LOGINMDP.bin')\n",
    "    histo = [0 for j in range(42)]\n",
    "    result = []\n",
    "\n",
    "    for i in range(info[\"nb_trames\"] - 1):\n",
    "        __predict(model, frames[i])\n",
    "        _, index = debrief(__predict(model, frames[i]))\n",
    "        histo[index] += 1\n",
    "        if i % 15 == 0:\n",
    "            print(i / info[\"nb_trames\"])\n",
    "            #if result == [] or result[-1] != labels[np.argmax(histo)]:\n",
    "            m = np.argmax(histo)\n",
    "            result.append(labels[m])\n",
    "            histo[m] = 0\n",
    "            #m = np.argmax(histo)\n",
    "            #result[-1].append(labels[m])\n",
    "            histo = [0 for j in range(42)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = keylogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
